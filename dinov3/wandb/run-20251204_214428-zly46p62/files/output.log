I20251204 21:44:30 3324541 dinov3 train.py:433] Initialized Weights & Biases run: swept-capybara-44
[32mI20251204 21:44:30 3324541 dinov3 ssl_meta_arch.py:784] [0mGetting paramer groups for backbone
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mcls_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmask_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mpatch_embed.proj.weight: lr_multiplier: 0.05083731656658002, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mpatch_embed.proj.bias: lr_multiplier: 0.05083731656658002, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.0.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.1.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.2.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.3.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.4.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.5.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.6.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.7.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.8.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.9.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.10.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mblocks.11.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mnorm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mnorm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 ssl_meta_arch.py:772] [0mfusing param groups
[32mI20251204 21:44:30 3324541 dinov3 ssl_meta_arch.py:784] [0mGetting paramer groups for dino_head
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mlast_layer.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 ssl_meta_arch.py:772] [0mfusing param groups
[32mI20251204 21:44:30 3324541 dinov3 ssl_meta_arch.py:784] [0mGetting paramer groups for ibot_head
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mmlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
[32mI20251204 21:44:30 3324541 dinov3 param_groups.py:168] [0mlast_layer.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
[32mI20251204 21:44:30 3324541 dinov3 ssl_meta_arch.py:772] [0mfusing param groups
[32mI20251204 21:44:30 3324541 dinov3 train.py:153] [0mSchedulers ready.
[32mI20251204 21:44:31 3324541 dinov3 train.py:456] [0mPretrained weights found at /bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/checkpoints/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth and loaded
[32mI20251204 21:44:31 3324541 dinov3 train.py:457] [0mIncompatible keys in student: _IncompatibleKeys(missing_keys=[], unexpected_keys=['storage_tokens', 'blocks.0.attn.qkv.bias_mask', 'blocks.1.attn.qkv.bias_mask', 'blocks.2.attn.qkv.bias_mask', 'blocks.3.attn.qkv.bias_mask', 'blocks.4.attn.qkv.bias_mask', 'blocks.5.attn.qkv.bias_mask', 'blocks.6.attn.qkv.bias_mask', 'blocks.7.attn.qkv.bias_mask', 'blocks.8.attn.qkv.bias_mask', 'blocks.9.attn.qkv.bias_mask', 'blocks.10.attn.qkv.bias_mask', 'blocks.11.attn.qkv.bias_mask'])
[32mI20251204 21:44:31 3324541 dinov3 train.py:462] [0mIncompatible keys in teacher: _IncompatibleKeys(missing_keys=[], unexpected_keys=['storage_tokens', 'blocks.0.attn.qkv.bias_mask', 'blocks.1.attn.qkv.bias_mask', 'blocks.2.attn.qkv.bias_mask', 'blocks.3.attn.qkv.bias_mask', 'blocks.4.attn.qkv.bias_mask', 'blocks.5.attn.qkv.bias_mask', 'blocks.6.attn.qkv.bias_mask', 'blocks.7.attn.qkv.bias_mask', 'blocks.8.attn.qkv.bias_mask', 'blocks.9.attn.qkv.bias_mask', 'blocks.10.attn.qkv.bias_mask', 'blocks.11.attn.qkv.bias_mask'])
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:50] [0m###################################
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:51] [0mUsing data augmentation parameters:
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:52] [0mglobal_crops_scale: [0.32, 1.0]
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:53] [0mlocal_crops_scale: [0.05, 0.32]
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:54] [0mlocal_crops_number: 8
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:55] [0mglobal_crops_size: 256
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:56] [0mlocal_crops_size: 112
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:57] [0mgram_crops_size: None
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:58] [0mgram_teacher_no_distortions: False
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:59] [0mteacher_no_color_jitter: False
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:60] [0mlocal_crops_subset_of_global_crops: False
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:61] [0mpatch_size if local_crops_subset_of_global_crops: 16
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:62] [0mshare_color_jitter: False
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:63] [0mhorizontal flips: True
[32mI20251204 21:44:31 3324541 dinov3 augmentations.py:64] [0m###################################
[32mI20251204 21:44:31 3324541 dinov3 loaders.py:102] [0musing dataset: "Cholec80:root=/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/data/cholec80/shards/shard-{000001..000046}.tar"
[32mI20251204 21:44:31 3324541 dinov3 loaders.py:230] [0musing PyTorch data loader
[32mI20251204 21:44:31 3324541 dinov3 loaders.py:246] [0minfinite data loader
I20251204 21:44:31 3324541 dinov3 train.py:491] Starting training from iteration 0
[33mW20251204 21:44:42 3324541 py.warnings warnings.py:110] [0m/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/site-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  return torch._C._get_cublas_allow_tf32()

[32mI20251204 21:45:05 3324541 dinov3 helpers.py:105] [0mTraining  [     0/125000]  eta: 49 days, 6:40:55  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6669 (16.6669)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1094 (11.1094)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1051 (11.1051)  koleo_loss: 0.0166 (0.0166)  ibot_loss: 5.5547 (5.5547)  backbone_grad_norm: 4.6110 (4.6110)  dino_head_grad_norm: 0.0126 (0.0126)  ibot_head_grad_norm: 0.0172 (0.0172)  time: 34.061241  data: 5.069011  mem: 3533  (max mem: 27739)
[32mI20251204 21:45:12 3324541 dinov3 helpers.py:105] [0mTraining  [    10/125000]  eta: 5 days, 11:27:47  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6662 (16.6664)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1096 (11.1096)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1048 (11.1048)  koleo_loss: 0.0137 (0.0141)  ibot_loss: 5.5546 (5.5545)  backbone_grad_norm: 3.3694 (4.0500)  dino_head_grad_norm: 0.0119 (0.0121)  ibot_head_grad_norm: 0.0171 (0.0170)  time: 3.786445  data: 0.460940  mem: 3533  (max mem: 28756)
[32mI20251204 21:45:20 3324541 dinov3 helpers.py:105] [0mTraining  [    20/125000]  eta: 3 days, 9:26:47  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6656 (16.6658)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1097 (11.1096)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1047 (11.1047)  koleo_loss: 0.0081 (0.0110)  ibot_loss: 5.5545 (5.5545)  backbone_grad_norm: 3.9491 (4.4036)  dino_head_grad_norm: 0.0119 (0.0120)  ibot_head_grad_norm: 0.0168 (0.0168)  time: 0.760272  data: 0.000127  mem: 3533  (max mem: 28756)
[32mI20251204 21:45:28 3324541 dinov3 helpers.py:105] [0mTraining  [    30/125000]  eta: 2 days, 15:42:29  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6616 (16.6638)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1096 (11.1096)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1046 (11.1047)  koleo_loss: -0.0104 (0.0015)  ibot_loss: 5.5544 (5.5545)  backbone_grad_norm: 3.3634 (3.9770)  dino_head_grad_norm: 0.0122 (0.0121)  ibot_head_grad_norm: 0.0169 (0.0169)  time: 0.762074  data: 0.000113  mem: 3533  (max mem: 28756)
[32mI20251204 21:45:35 3324541 dinov3 helpers.py:105] [0mTraining  [    40/125000]  eta: 2 days, 6:36:28  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6582 (16.6616)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1095 (11.1096)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1046 (11.1047)  koleo_loss: -0.0283 (-0.0099)  ibot_loss: 5.5544 (5.5545)  backbone_grad_norm: 3.6753 (4.4237)  dino_head_grad_norm: 0.0123 (0.0121)  ibot_head_grad_norm: 0.0169 (0.0169)  time: 0.761743  data: 0.000119  mem: 3533  (max mem: 28756)
[32mI20251204 21:45:43 3324541 dinov3 helpers.py:105] [0mTraining  [    50/125000]  eta: 2 days, 1:04:50  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6510 (16.6592)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1094 (11.1096)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1046 (11.1047)  koleo_loss: -0.0645 (-0.0212)  ibot_loss: 5.5544 (5.5545)  backbone_grad_norm: 3.8127 (4.1549)  dino_head_grad_norm: 0.0123 (0.0122)  ibot_head_grad_norm: 0.0171 (0.0170)  time: 0.761303  data: 0.000128  mem: 3533  (max mem: 28756)
[32mI20251204 21:45:51 3324541 dinov3 helpers.py:105] [0mTraining  [    60/125000]  eta: 1 day, 21:23:11  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6451 (16.6566)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1094 (11.1095)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1044 (11.1046)  koleo_loss: -0.0908 (-0.0339)  ibot_loss: 5.5542 (5.5544)  backbone_grad_norm: 3.0855 (3.9540)  dino_head_grad_norm: 0.0125 (0.0123)  ibot_head_grad_norm: 0.0175 (0.0172)  time: 0.763579  data: 0.000135  mem: 3533  (max mem: 28756)
[32mI20251204 21:45:58 3324541 dinov3 helpers.py:105] [0mTraining  [    70/125000]  eta: 1 day, 18:44:24  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6403 (16.6539)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1093 (11.1095)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1041 (11.1046)  koleo_loss: -0.1123 (-0.0468)  ibot_loss: 5.5540 (5.5543)  backbone_grad_norm: 2.9405 (3.8061)  dino_head_grad_norm: 0.0128 (0.0124)  ibot_head_grad_norm: 0.0182 (0.0173)  time: 0.766274  data: 0.000154  mem: 3533  (max mem: 28756)
[32mI20251204 21:46:06 3324541 dinov3 helpers.py:105] [0mTraining  [    80/125000]  eta: 1 day, 16:45:02  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6360 (16.6515)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1091 (11.1094)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1043 (11.1045)  koleo_loss: -0.1328 (-0.0583)  ibot_loss: 5.5539 (5.5543)  backbone_grad_norm: 2.3623 (3.6558)  dino_head_grad_norm: 0.0131 (0.0125)  ibot_head_grad_norm: 0.0184 (0.0175)  time: 0.767561  data: 0.000152  mem: 3533  (max mem: 28756)
[32mI20251204 21:46:14 3324541 dinov3 helpers.py:105] [0mTraining  [    90/125000]  eta: 1 day, 15:11:41  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6318 (16.6493)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1090 (11.1094)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1043 (11.1045)  koleo_loss: -0.1523 (-0.0690)  ibot_loss: 5.5538 (5.5542)  backbone_grad_norm: 1.9832 (3.4695)  dino_head_grad_norm: 0.0134 (0.0126)  ibot_head_grad_norm: 0.0187 (0.0176)  time: 0.767608  data: 0.000182  mem: 3533  (max mem: 28756)
[32mI20251204 21:46:21 3324541 dinov3 helpers.py:105] [0mTraining  [   100/125000]  eta: 1 day, 13:56:44  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6295 (16.6472)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1089 (11.1093)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1041 (11.1045)  koleo_loss: -0.1621 (-0.0785)  ibot_loss: 5.5535 (5.5541)  backbone_grad_norm: 2.0089 (3.3678)  dino_head_grad_norm: 0.0136 (0.0127)  ibot_head_grad_norm: 0.0194 (0.0179)  time: 0.767016  data: 0.000180  mem: 3533  (max mem: 28756)
[32mI20251204 21:46:29 3324541 dinov3 helpers.py:105] [0mTraining  [   110/125000]  eta: 1 day, 12:56:44  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6276 (16.6454)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1089 (11.1093)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1037 (11.1044)  koleo_loss: -0.1699 (-0.0874)  ibot_loss: 5.5535 (5.5541)  backbone_grad_norm: 2.4068 (3.2965)  dino_head_grad_norm: 0.0139 (0.0128)  ibot_head_grad_norm: 0.0199 (0.0181)  time: 0.770803  data: 0.000205  mem: 3533  (max mem: 28756)
[32mI20251204 21:46:37 3324541 dinov3 helpers.py:105] [0mTraining  [   120/125000]  eta: 1 day, 12:05:30  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6249 (16.6435)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1088 (11.1092)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1037 (11.1044)  koleo_loss: -0.1846 (-0.0958)  ibot_loss: 5.5533 (5.5540)  backbone_grad_norm: 2.2305 (3.2268)  dino_head_grad_norm: 0.0141 (0.0129)  ibot_head_grad_norm: 0.0205 (0.0183)  time: 0.771463  data: 0.000204  mem: 3533  (max mem: 28756)
[32mI20251204 21:46:44 3324541 dinov3 helpers.py:105] [0mTraining  [   130/125000]  eta: 1 day, 11:21:58  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6226 (16.6419)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1084 (11.1092)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1036 (11.1043)  koleo_loss: -0.1934 (-0.1033)  ibot_loss: 5.5531 (5.5539)  backbone_grad_norm: 2.2877 (3.2002)  dino_head_grad_norm: 0.0143 (0.0131)  ibot_head_grad_norm: 0.0209 (0.0185)  time: 0.767807  data: 0.000145  mem: 3533  (max mem: 28756)
[32mI20251204 21:46:52 3324541 dinov3 helpers.py:105] [0mTraining  [   140/125000]  eta: 1 day, 10:44:27  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6217 (16.6404)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1084 (11.1091)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1036 (11.1042)  koleo_loss: -0.1943 (-0.1100)  ibot_loss: 5.5529 (5.5538)  backbone_grad_norm: 2.3521 (3.1640)  dino_head_grad_norm: 0.0144 (0.0132)  ibot_head_grad_norm: 0.0214 (0.0187)  time: 0.767027  data: 0.000137  mem: 3533  (max mem: 28756)
[32mI20251204 21:46:58 3324541 dinov3 train.py:528] [0mGarbage collection
[32mI20251204 21:47:01 3324541 dinov3 helpers.py:105] [0mTraining  [   150/125000]  eta: 1 day, 10:24:05  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6199 (16.6391)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1083 (11.1090)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1034 (11.1042)  koleo_loss: -0.1992 (-0.1160)  ibot_loss: 5.5527 (5.5538)  backbone_grad_norm: 2.4478 (3.1645)  dino_head_grad_norm: 0.0145 (0.0133)  ibot_head_grad_norm: 0.0218 (0.0189)  time: 0.810869  data: 0.000119  mem: 3533  (max mem: 28756)
[32mI20251204 21:47:08 3324541 dinov3 helpers.py:105] [0mTraining  [   160/125000]  eta: 1 day, 9:55:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6185 (16.6377)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1079 (11.1090)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1030 (11.1041)  koleo_loss: -0.2070 (-0.1218)  ibot_loss: 5.5527 (5.5537)  backbone_grad_norm: 2.8788 (3.1268)  dino_head_grad_norm: 0.0146 (0.0133)  ibot_head_grad_norm: 0.0220 (0.0191)  time: 0.812983  data: 0.000127  mem: 3533  (max mem: 28756)
[32mI20251204 21:47:16 3324541 dinov3 helpers.py:105] [0mTraining  [   170/125000]  eta: 1 day, 9:29:37  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6165 (16.6365)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1077 (11.1089)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1026 (11.1040)  koleo_loss: -0.2129 (-0.1272)  ibot_loss: 5.5522 (5.5536)  backbone_grad_norm: 1.9756 (3.0893)  dino_head_grad_norm: 0.0147 (0.0134)  ibot_head_grad_norm: 0.0224 (0.0193)  time: 0.769431  data: 0.000134  mem: 3533  (max mem: 28756)
[32mI20251204 21:47:24 3324541 dinov3 helpers.py:105] [0mTraining  [   180/125000]  eta: 1 day, 9:06:41  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6151 (16.6353)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1072 (11.1088)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1025 (11.1039)  koleo_loss: -0.2168 (-0.1322)  ibot_loss: 5.5519 (5.5535)  backbone_grad_norm: 1.9717 (3.2021)  dino_head_grad_norm: 0.0148 (0.0135)  ibot_head_grad_norm: 0.0226 (0.0195)  time: 0.767893  data: 0.000130  mem: 3533  (max mem: 28756)
[32mI20251204 21:47:31 3324541 dinov3 helpers.py:105] [0mTraining  [   190/125000]  eta: 1 day, 8:46:42  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  total_loss: 16.6144 (16.6341)  local_batch_size: 64.0000 (64.0000)  global_batch_size: 64.0000 (64.0000)  dino_local_crops_loss: 11.1072 (11.1087)  dino_local_loss_weight: 1.0000 (1.0000)  dino_global_crops_loss: 11.1023 (11.1038)  koleo_loss: -0.2207 (-0.1368)  ibot_loss: 5.5515 (5.5534)  backbone_grad_norm: 2.1260 (3.1548)  dino_head_grad_norm: 0.0149 (0.0136)  ibot_head_grad_norm: 0.0230 (0.0197)  time: 0.770378  data: 0.000146  mem: 3533  (max mem: 28756)
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f06e0d0a340>
Traceback (most recent call last):
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1599, in _shutdown_workers
    self._worker_result_queue.put((None, None))
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/multiprocessing/queues.py", line 94, in put
    self._start_thread()
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/multiprocessing/queues.py", line 166, in _start_thread
    self._thread = threading.Thread(
                   ^^^^^^^^^^^^^^^^^
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/threading.py", line 905, in __init__
    self._started = Event()
                    ^^^^^^^
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/threading.py", line 563, in __init__
    self._cond = Condition(Lock())
                 ^^^^^^^^^^^^^^^^^
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/threading.py", line 265, in __init__
    self._waiters = _deque()
                    ^^^^^^^^
KeyboardInterrupt:
Traceback (most recent call last):
  File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/train.py", line 725, in <module>
    .get("iteration", -1)
    ^^^^^^
  File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/train.py", line 721, in main
    model.init_weights()
  File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/train.py", line 545, in do_train
    wd = wd_schedule[it]

  File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/ssl_meta_arch.py", line 426, in forward_backward
    self.backprop_loss(loss_accumulator)
  File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/ssl_meta_arch.py", line 711, in backprop_loss
    loss.backward()
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/train.py", line 725, in <module>
[rank0]:     .get("iteration", -1)
[rank0]: ^^
[rank0]:   File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/train.py", line 721, in main
[rank0]:     model.init_weights()
[rank0]: ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/train.py", line 545, in do_train
[rank0]:     wd = wd_schedule[it]
[rank0]:
[rank0]:   File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/ssl_meta_arch.py", line 426, in forward_backward
[rank0]:     self.backprop_loss(loss_accumulator)
[rank0]:   File "/bd_byta6000i0/users/surgicaldinov2/kyyang/surgicaldinov3/dinov3/dinov3/train/ssl_meta_arch.py", line 711, in backprop_loss
[rank0]:     loss.backward()
[rank0]:   File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/bd_byta6000i0/users/surgicaldinov2/miniforge3/envs/da3/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: KeyboardInterrupt
